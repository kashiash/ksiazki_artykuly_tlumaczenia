# Czy AI zaszkodzi programistom ?

https://youtu.be/uuvjOvAdnOk?si=JEYMeAak34mZXtRu

Co by było, gdyby wszystkie branże zostały zastąpione przez sztuczną inteligencję? Na przykład dziedzina każdego została zastąpiona przez sztuczną inteligencję i żaden człowiek nie miał pracy. Czy naprawdę wszyscy straciliby pracę? Nie. Ludzie będą robić to, co robią i zawsze robili. Tworzą nowe możliwości. Możliwości, o których w tej chwili nawet nie wiemy. I będzie to wymagało ludzi technicznych. Ale po prostu nie wiemy, jakie są te możliwości. To ekscytujące. Co słychać? Tu Travis z Travis.media. 

Dzisiaj przyjrzymy się krótko bardzo dosadnemu, ale przemyślanemu filmowi na temat przyszłości sztucznej inteligencji i programistów. Tak, pójdziemy tam. Pewien profesor, dr Matt Welsh, wygłosił wykład dla grupy studentów informatyki z Harvardu. Wykład nosił tytuł "**Duże modele językowe u schyłku programowania**". "To dość odważny temat do zaprezentowania grupie studentów uczących się programowania. 

Tak czy inaczej, wykład był nieco przerażający, ale myślę, że musimy o tym porozmawiać. I myślę, że musimy poważnie potraktować tę ostrożność, abyśmy mogli dowiedzieć się, gdzie i kiedy pójść dalej. W dalszej części filmu chciałbym podzielić się z wami trzema kluczowymi wnioskami, które pomogą wam utrzymać postęp w tej szybko zmieniającej się branży. Jak już wiesz, jestem wielkim zwolennikiem nauki kodowania już teraz. Moje stanowisko się nie zmieniło i omówię dlaczego w dalszej części filmu. Nie pomaga jednak zamiatanie obaw pod dywan i zachowywanie się tak, jakbyśmy nie znajdowali się w kluczowym punkcie historii. 

Dzisiaj przyjrzymy się trzem fragmentom tego wystąpienia. I pamiętaj, aby skomentować swoje opinie poniżej, ponieważ myślę, że będzie to świetna dyskusja. Zaczniemy więc od klipu pierwszego, który jest przesłanką wykładu. Myślę, że to, co chcę tutaj powiedzieć, to to, że jesteśmy teraz w erze, w której mamy maszyny, które mogą przyjmować język naturalny i generować wyniki, wyniki algorytmiczne, wyniki obliczeniowe, ale dla których żaden człowiek nie napisał programu w niczym przypominającym konwencjonalny język programowania. Twierdzę, że modele te będą w tym tak dobre, że cała nasza koncepcja programowania komputerów zostanie z czasem zastąpiona instruowaniem modeli językowych, by robiły rzeczy za nas. Okej, takie jest założenie wykładu. 

To jest miejsce, w którym obecnie się znajdujemy. Jesteśmy więc obecnie w tym punkcie historii. Mamy teraz maszyny, które mogą przyjmować język naturalny lub podpowiedzi i generować wyniki algorytmiczne i obliczeniowe. Nasz model ostatecznie zmieni się z naszego programowania na przede wszystkim instruowanie modeli językowych, aby robiły rzeczy za nas. Takie jest założenie. To podstawa tego wykładu. Powiem szybko, że jesteśmy w tym momencie historii. 

Na 100% powinieneś używać GitHub Copilot, ChadGBT, VO by Vercell, czegoś takiego, aby pomóc w programowaniu. Jeśli tego nie robisz, nadal jeździsz konno, podczas gdy wszyscy inni kupują samochód. Na przykład, jeśli musisz użyć Pythona w pakiecie żądań, aby pobrać dane z interfejsu API i zapisać je w arkuszu kalkulacyjnym, możesz użyć tych narzędzi do stworzenia początkowego planu, zamiast zaczynać od zera. Te narzędzia są po to, aby ci pomóc i albo zaczniesz z nich korzystać i znajdziesz korzyści na swój własny sposób, albo skończysz pracując wolniej niż wszyscy inni. Każdy powinien korzystać z tych narzędzi. Tak więc ten następny klip, to przerażająca część wykładu. Jest to oszacowanie, w jaki sposób sztuczna inteligencja może zastąpić codziennego programistę. Teraz myślę, że jest to nieco odważne twierdzenie, biorąc pod uwagę toczące się obecnie bitwy etyczne, niedokładności i wiarygodność modeli, które mogą pracować samodzielnie. Jest to jednak interesujący wniosek, który może pojawić się w przyszłości. I znowu, opowiem o tym za chwilę, ale obejrzyj ten klip. 

Klip drugi. Ile kosztuje zastąpienie jednego ludzkiego programisty sztuczną inteligencją? Cóż, policzyłem. Powiedzmy więc, że typowa pensja inżyniera oprogramowania w Dolinie Krzemowej lub Seattle wynosi około 220 000 USD rocznie. To tylko pensja podstawowa, nie obejmuje świadczeń, nie obejmuje pakietów kapitałowych, nie obejmuje darmowego lunchu w kręgielni i tym podobnych rzeczy. Załóżmy więc, że te rzeczy kosztują 92 000 USD rocznie. Jest to, ponownie, nieco konserwatywne założenie. Zatem całkowity koszt dla pracodawcy wynosi około 300 000 USD, 312 000 USD za jeden SWE. Ile jest dni roboczych w roku? Około 260. Zatrudnienie pracownika SWE w jednej z tych firm kosztuje więc 1200 dolarów dziennie. 

Jestem inżynierem oprogramowania, SWE. W porządku. Ok, więc policzmy. Jak myślisz, ile linii kodu przeciętny programista sprawdza w bazie kodu każdego dnia? Mam na myśli sfinalizowane, przetestowane, sprawdzone i zatwierdzone linie kodu. Większość z nas, którzy pracowali w branży, wie, że mediana wynosi zero, ponieważ jest tak wiele dni, w których czekasz na kogoś innego lub jesteś na spotkaniach przez cały dzień, nic nie zrobiłeś, nie sprawdziłeś tego. Ale bądźmy hojni i powiedzmy, że jest ich około 100. Wiem, że 100 nie brzmi jak dużo. Ludzie mówią: "Ale ja programowałem cały dzień! " Tak, ale 90% twojego kodu ostatecznie wyrzuciłeś lub ktoś go przejrzał i powiedział, że nie jest dobry, musisz go przepisać, próbowałeś dowiedzieć się, co zrobić, przebudowywałeś go. Tak więc ostateczny wynik to około 100 linii kodu dziennie. To jest ostateczny wynik. 

Ile tokenów modelu GPT-3? Mniej więcej 10 tokenów na linię. A koszt GPT-3, w rzeczywistości jest to prawdopodobnie trochę nieaktualne, ale w czasie, gdy robiłem ten slajd, było to 0,02 USD za 1000 tokenów. Jeśli więc policzyć, to całkowity koszt produkcji jednego ludzkiego programisty na GPT-3 wynosi 0,12 USD. Jest to współczynnik 10 000. To powinno nas wszystkich przestraszyć. To przerażająca statystyka. Mówi on, że za 100 linii kodu dziennie, zamiast płacić inżynierowi oprogramowania 1200 dolarów dziennie za napisanie tego, sztuczna inteligencja zrobi to za 0,12 dolara lub centa. 

Chodzi mi o to, czego wszyscy się boimy. To jest ich największe zmartwienie. Czy sztuczna inteligencja zabierze mi pracę? Cóż, jeśli obniży koszty 10 000 razy, to tak. Ale gdyby tak się stało, jak by to wyglądało? Jak wyglądałby taki przepływ pracy? Cóż, w tym ostatnim klipie podaje przykład tego, jak może wyglądać przyszłość z tym modelem. Co będą robić inżynierowie oprogramowania? Zobacz ten klip. 

Ale jeśli wyobrazisz sobie, jak może wyglądać zespół programistów w przyszłości, myślę, że jest to bardzo prawdopodobne podejście, które polega na tym, że masz menedżera produktu. Prawdopodobnie nadal jest to człowiek, który bierze wymagania biznesowe i produktowe, wymagania użytkowników i tłumaczy je na jakąś formę, prawdopodobnie angielski, może trochę techniczny angielski, który następnie można dostarczyć sztucznej inteligencji, armii generatorów kodu sztucznej inteligencji. Generatory kodu AI dają ci całą masę kodu i prawdopodobnie jeszcze przez jakiś czas ludzie będą czytać i sprawdzać kod, aby upewnić się, że robi to, co powinien. Tak więc zespół programistów przyszłości może składać się z kierowników projektów, sztucznej inteligencji piszącej kod, a następnie recenzentów kodu. I o ile ty lub ja nie zajmiemy się zarządzaniem produktem, prawdopodobnie będziemy recenzentami kodu w tym modelu, upewniając się, że kod faktycznie działa, że robi to, co zamierzał, i ogólnie działa zgodnie z tym, jak menedżer produktu pozycjonuje produkt lub projekt. To jest opcja. 

Co więc robimy z tymi wszystkimi informacjami? Co zrobić w takim przypadku? Od lat na YouTube pomagam ludziom uczyć się kodowania i zachęcam ich do wejścia do branży. Czy teraz radzę inaczej? Nie. Pozwól, że wyjaśnię. Zamierzam dać ci trzy wnioski z tego filmu i zachęcam do obejrzenia całości. To dość fascynujące. Wiele z tego pominąłem. Ale znajduje się na stronie CS50, stronie CS50 na YouTube i warto poświęcić mu swój czas. 

Ale oto moje trzy wnioski z tego filmu. 

1. Po pierwsze, branża się zmienia. To nie jest zła rzecz. Zmiany są dobre. Postęp jest dobry. Ale nie dla tych, którzy je ignorują i pozostają w tyle. Rozmowy takie jak ta są pomocne nie tylko w rozpoczęciu przetwarzania tego, dokąd zmierzają rzeczy, ale także w tym, gdzie się znajdujesz. Jeśli nie korzystasz z GPT, Copilota lub podobnego pomocnika AI, to sugerowałbym, abyś spróbował i zobaczył, czy to ci pomoże i pomoże ci stać się szybszym i bardziej wydajnym w swojej pracy. To nigdzie nie pójdzie. Sugerowałbym również zbudowanie jakiejś aplikacji z OpenAI API, aby się z nią zapoznać. Mam film, w którym pokazuję, jak zbudować bota do rozmów kwalifikacyjnych na czacie GPT za pomocą FastAPI i React. Link do niego umieszczę powyżej. Jeśli nie masz żadnych pomysłów, możesz po prostu postępować zgodnie z tym samouczkiem. Sugerowałbym jednak skorzystanie z tych narzędzi i zapoznanie się z nimi. 
2. Po drugie, nie powinieneś rezygnować z kariery programisty. Pomyśl o zawodach, które można łatwo zastąpić, takich jak kasjerzy, przedstawiciele obsługi klienta, kasjerzy bankowi, asystenci prawni. Mam na myśli, czy naprawdę potrzebuję kogoś, osoby, która przyjmie moje zamówienie w McDonald's? Jasne, miło jest wchodzić w interakcje z ludźmi, ale komputer prawdopodobnie zrobi to szybciej. Właśnie zobaczyłem dzisiaj, że twórca Chipotle ma zamiar uruchomić nową bezmięsną restaurację na Manhattanie, która wymaga tylko trzech osób. Reszta to roboty. To będzie przyszłość. Ale kiedy myślisz o sztucznej inteligencji, robotach, uczeniu maszynowym itp. o czym myślisz? Cóż, myślisz o programowaniu. Myślisz o kodzie. Myślisz o ludziach technicznych. Nie myślisz o kasjerach i wprowadzaniu danych. To dziedzina techniczna. A oto co ja myślę. Myślę, że każdy, kto rozumie komputery i programowanie komputerowe, będzie wartościowy. Być może będzie to podstawowa umiejętność dla przyszłych zawodów, które nie zostały jeszcze stworzone, a które ty już posiadasz. Co by było, gdyby wszystkie branże zostały zastąpione przez sztuczną inteligencję? Jakby każda dziedzina została zastąpiona przez sztuczną inteligencję i żaden człowiek nie miałby pracy? Czy naprawdę wszyscy zostaliby bez pracy? Nie. Ludzie będą robić to, co robią i zawsze robili. Tworzą nowe możliwości, możliwości, o których w tej chwili nawet nie wiadomo. I będzie to wymagało ludzi technicznych. Ale jeszcze nie wiemy, jakie to możliwości. To ekscytujące. Umiejętność programowania może być postrzegana jako pakiet, który pozwala wejść w nową erę możliwości. To podstawowy zestaw umiejętności. Nie myśl więc w kategoriach ograniczania miejsc pracy, na przykład, że moja praca zostanie przejęta przez sztuczną inteligencję. Myśl o tym raczej jako o ogromnym rozszerzeniu nowych możliwości, które będą wymagały ludzi technicznych, aby wprowadzić je w życie. 
3. Trzecim kluczowym wnioskiem jest to, że jeszcze tam nie jesteśmy. Chociaż OpenAI Dev Day wprowadził ogromny skok w rozwoju sztucznej inteligencji, to wciąż jest to tylko Atari. Jest tak wcześnie. Po prostu nie ufamy jeszcze AI w szerszej perspektywie. Toczą się batalie prawne. Pojawia się mnóstwo błędów. Niedawno na LinkedIn widziałem post o GPT-4. Przeprowadzono to badanie, opracowano ten dokument, ale zasadniczo wyniki były następujące. Dokładność GPT-4 w wielu zwrotach, co oznacza, że rozmowa obraca się więcej niż raz. Zadajesz pytanie, a następnie przechodzisz do czegoś zupełnie innego. Dokładność wieloobrotowa GPT-4 dla edycji PPT wyniosła tylko 6%. A nawet dokładność GPT-4 dla pojedynczego obrotu była niska i wynosiła 72% przy tworzeniu i 28% przy edycji. 



Istnieje cały artykuł dokumentujący wszystkie te rzeczy, ale sztuczna inteligencja ma przed sobą długą drogę. Nie jesteśmy jeszcze gotowi, by w pełni ją wykorzystać. Daleko nam do tego, by pozwolić sztucznej inteligencji na programowanie naszych produktów. Niektóre organizacje nawet nie wpuszczają AI za drzwi. Nawet jeśli jesteś na etapie, na którym dopiero zaczynasz uczyć się kodowania, powiedziałbym, że uczysz się cennej umiejętności, która zostanie wykorzystana w przyszłości. Obecnie będzie ona wykorzystywana zgodnie z celami, do których dążysz, ale nawet w przyszłości będzie to cenna umiejętność. W jaki sposób? Tego jeszcze nie wiem. To znaczy, może nadal będziesz programistą utrzymującym dużą witrynę internetową lub architektem chmury lub inżynierem DevOps automatyzującym i specyfikującym systemy. I chociaż sztuczna inteligencja potrafi pisać kod, jest o wiele więcej aspektów bycia programistą, które nie wymagają pisania kodu. A ten ludzki aspekt jest tak istotny dla wielu firm. Tak więc ponownie uważam, że nauka kodowania jest nadal tak istotną umiejętnością w tej szeroko zakrojonej branży, ale taką, która pozwoli na podstawowy zestaw umiejętności dla wszystkich przyszłych miejsc pracy. Ponieważ sztuczna inteligencja staje się coraz bardziej popularna i coraz bardziej dokładna i godna zaufania. 





Wykład Mata



Witamy wszystkich. Dzisiaj dołączył do nas dr Matt Welsh, a pod koniec wykładu dołączy do nas również pizza, którą będziemy serwować wychodzącym ludziom, a także jako okazję do bardziej swobodnej rozmowy z Mattem pod koniec. Poznałem Matta, gdy byłem na studiach magisterskich i spędziłem sporo czasu z nim i jego studentami, gdy skupiał się szczególnie na tak zwanych sieciach czujników, które są rozproszonymi sieciami bardzo małych urządzeń o niskim poborze mocy i zasobach, co sprawiało, że w tamtym czasie bardzo trudno było napisać kod, który je łączy i ogólnie rozwiązuje problemy. Wśród problemów, nad którymi pracowali niektórzy z moich kolegów z klasy, było na przykład monitorowanie wulkanów i integralności mostów, a w moim własnym interesie było stworzenie sieci typu mesh w medycynie ratunkowej, aby mogli rozmawiać między sobą bez kabli lub bez centralnego dostępu. Od tego czasu Matt pracował na pełen etat w Google, a ostatnio w fixi. ai. I jak można było wywnioskować z dzisiejszego opisu, przewiduje on przyszłość, w której komputery będą za nas pisać kod. Jeśli więc zmagasz się z CS50, 61, 161 lub czymkolwiek pomiędzy, nie martw się. Sztuczna inteligencja już tu jest, podobnie jak dr Matt Welsh. 



 Dzięki, David. Dzięki za zaproszenie. Minęło, nie wiem, 13 czy coś koło tego, 12 lat odkąd wygłosiłem wykład na Harvardzie. Zobaczymy więc, czy wciąż to mam. Żartowałem wczoraj z Davidem Parksem, który jest teraz dziekanem, a on i ja byliśmy w pewnym sensie rówieśnikami, kiedy byłem tu na wydziale. Powiedziałem, że to niezwykłe. Gratuluję Davidowi zostania dziekanem CSE. Myślę, że nie jesteśmy jeszcze wystarczająco starzy, by być dziekanami. A potem zdałem sobie sprawę, że jesteśmy. W każdym razie, w porządku. Jestem tu, by powiedzieć, że dziedzina informatyki jest skazana na zagładę, OK? I tak naprawdę mam to na myśli, choć ujmę to w nieco humorystyczny sposób, że jeśli myślisz o informatyce, to o co chodzi w tej dziedzinie? Co ona oznacza? Skąd się wzięła? Jaka jest jej podstawowa idea? Chodzi o to, aby wziąć pomysł, algorytm, koncepcję lub strukturę danych i przetłumaczyć je na program, który może być generalnie uruchomiony przez maszynę o architekturze von Neumanna, prawda? OK, więc to jest informatyka w pigułce. Problem polega na tym, że celem informatyki zawsze było takie podstawowe założenie lub aksjomat, że programy, o których wszyscy tutaj mówimy, zostały zaimplementowane, utrzymywane i muszą być zrozumiałe dla ludzi, prawda? Że jeśli wydrukuję kod programu, człowiek, jakiś człowiek, może nie każdy, ale przynajmniej osoba, która go napisała, jeśli nie ktoś inny, może go zrozumieć. I tu pojawia się problem, prawda? Ludzie są do bani we wszystkich tych trzech rzeczach. Jesteśmy okropni w pisaniu programów, jesteśmy okropni w ich utrzymywaniu i jesteśmy absolutnie okropni w ich rozumieniu. Co to tak naprawdę oznacza dla tej dziedziny? Chcę więc postawić tezę, że 50 lat badań nad językami programowania nie zrobiło właściwie nic, by rozwiązać ten problem. Zajmujemy się tym już od dłuższego czasu. 50 lat to szmat czasu. Wciąż wymyślamy nowe języki, nowe koncepcje programowania, nowe abstrakcje, nowe typy danych i nowe metodologie dowodzenia. Ale żadna z rzeczy, które opracowaliśmy w zakresie narzędzi, języków, technik dowodowych, dokumentacji czy linterów nie rozwiązała tego problemu. I nie sądzę, by kolejne 50 lat miało go rozwiązać. Myślę, że idea budowania zautomatyzowanych narzędzi, które pomogą ludziom pisać lepsze oprogramowanie, już się wyczerpała. Jeśli się ze mną nie zgadzasz, spójrzmy na historię. Cofnijmy więc zegar aż do 1957 roku. To jest gra Conway's Game of Life zaimplementowana w Fortranie. Nie pamiętam, który to dialekt Fortranu, ale Fortran pojawił się około 1957 roku. Twierdzę tylko, że jest to naprawdę trudne do zrozumienia. Twierdzę, że nie możesz na to spojrzeć i jeśli nie masz pojęcia o intencjach programisty, co to do cholery robi? Mógłbyś to rozpracować. Można spędzić trochę czasu czytając to. Prawdopodobnie można to zrozumieć przy pewnym wysiłku, ale nie jest to trywialne. To nie jest proste. OK, więc staraliśmy się ułatwić programowanie. W 1964 roku wymyśliliśmy coś o nazwie BASIC. Nie jest to oryginalny BASIC. Miał on wiele dialektów, ponieważ pierwszy nie był wystarczająco dobry. Musieliśmy stale ulepszać ten język. To jest ten sam program w BASIC-u. Nie sądzę, by był łatwiejszy do zrozumienia. Mógłbym spędzić trochę czasu czytając go i przekonać samego siebie, że robi pewną rzecz, ale jest to dość trudne do zrozumienia. Więc wymyśliliśmy APL. To jest Conway's Game of Life w APL. Podnieś rękę, jeśli to rozumiesz, ale wiem, że na widowni jest pewnie kilka osób, które to rozumieją. [Ja nie. To język programowania tak skomplikowany, że do jego pisania potrzebna była specjalna klawiatura. Ale właśnie to uważaliśmy za praktykę tworzenia języków programowania w latach 60-tych. Z pewnością nie spełnia swojego zadania. No dobrze, mówiłem o rzeczach, które są trochę staromodne. A co z nowymi trendami? Porozmawiajmy o Rust. Wszyscy programują w Rust. To najnowsza i najlepsza rzecz od czasów krojonego chleba. Spędziłem dwa lata prowadząc inżynierię w startupie, który był całkowicie oparty na Rust. Prowadziłem duży zespół pełen programistów Rust. Właściwie to sam nauczyłem się Rusta, tak jakby. To jest ten sam program w Rust. Nie wiem, co z tym zrobić. Niezwykle trudno jest pisać programy, które są łatwe do zrozumienia, łatwe w utrzymaniu, łatwe do zrozumienia. Taki jest więc obecny stan rzeczy. W ciągu 50 lat doszliśmy od Fortrana do tego. Chcę tylko powiedzieć, że to nie zadziała. OK, skończyliśmy. Koniec gry. Więc co dalej? Oto jak piszę kod dzisiaj. To jest monit przekazywany do modelu GPT-4. Jest to część większego programu, który wczytuje tekst transkrypcji pochodzącej z kanału audio podcastu. Wprowadzamy transkrypcję do modelu. I dajemy mu te instrukcje. Mówimy: podsumuj następujący segment transkrypcji tego podcastu. Używaj tylko informacji w tekście. Nie używaj wielkich liter - to ważne, tak przy okazji. Wszystkie wielkie litery są bardzo ważne. Nie używaj żadnych informacji, które znasz o świecie. Uwzględnij tytuł podcastu, nazwę odcinka i nazwiska prelegentów, jeśli są znane. To angielskie zdanie koduje algorytm. Opisuje coś, co chcę zrobić z danymi wejściowymi i danymi wyjściowymi, których chcę, oraz moje oczekiwania dotyczące rodzaju rzeczy, które znajdują się w danych wyjściowych. Warto więc zwrócić uwagę na kilka rzeczy. Pierwszą rzeczą, na którą należy zwrócić uwagę, jest to, że nie sądzę, aby ktokolwiek mógł kiedykolwiek zapisać algorytm tego, co to ma zrobić w jakimkolwiek istniejącym języku programowania lub jakimkolwiek języku programowania, który prawdopodobnie wymyślimy w przyszłości. Jak napisać taki algorytm? Nie da się. Nie ma pseudokodu. Nie ma żadnego dowodu. Nie ma tu żadnej matematycznej symboliki. Inną rzeczą, na którą należy zwrócić uwagę, jest to, że przynajmniej dla mnie, nie wiem jak dla każdego z was, czy to rozumiecie? Czy rozumiesz, co to mówi? Czy to ma sens? Czy potrafisz to odczytać? Czy potrafisz zrozumieć, co to ma robić? Tak, oczywiście, prawda? Jest napisany prostym angielskim. Nawiasem mówiąc, nie musi to być angielski. Może być po mandaryńsku lub esperanto. [Czy wszyscy widzieliście XKCD o facecie, który wchodzi do domu swojego przyjaciela i mówi: OK, Alexa, zamów pięć ton kremowej kukurydzy. OK, Alexa, potwierdź zamówienie. W ten sposób upewnia się, że nikt nie ma głośnika, który go podsłuchuje. OK, więc chodzi o to, że teraz tak właśnie piszę kod. Zabawne jest to, że w dużej mierze jest to metoda prób i błędów oraz eksperymentowanie. Nawiasem mówiąc, to samo dzieje się, gdy piszę normalny kod komputerowy. Inną interesującą rzeczą jest to, że istnieje wiele subtelności w zakresie tego, jak instruujesz model i skąd wiesz, co zrobi z twoimi instrukcjami. Nie można napisać instrukcji, która mówi, że oto zestaw słów, których należy użyć, aby model zrobił x, y lub z. Trzeba po prostu wypróbować pewne rzeczy. W tym przypadku okazało się, że napis NIE wielkimi literami naprawdę pomógł, ponieważ naprawdę chciałem podkreślić ten punkt w modelu. Przypomina mi to inny język programowania, który ktoś wymyślił jakiś czas temu o nazwie InterCal. InterCal miał być jednym z tych niejasnych, a może satyrycznych, żartobliwych języków programowania. InterCal miał te interesujące funkcje, takie jak konieczność użycia słowa kluczowego PLEASE. Jeśli używałeś słowa kluczowego PLEASE zbyt często, kompilator odrzucał twój program. Jeśli nie używałeś go wystarczająco często, również odrzucał twój program. Okazało się, że funkcja ta była nieudokumentowana. To dokładnie to samo, co robimy dzisiaj, prawda? Musimy mówić PLEASE i DO NOT wielkimi literami, aby modele językowe robiły to, co chcemy. Do czego więc zmierzam? Myślę, że chcę powiedzieć, że jesteśmy teraz w erze, w której mamy maszyny, które mogą przyjmować język naturalny i generować wyniki, wyniki algorytmiczne, wyniki obliczeniowe, ale dla których żaden człowiek nie napisał programu w czymkolwiek przypominającym konwencjonalny język programowania. Twierdzę, że modele te będą w tym tak dobre, że cała nasza koncepcja programowania komputerów zostanie z czasem zastąpiona instruowaniem modeli językowych, by robiły rzeczy za nas. Przyjrzyjmy się zatem stanowi technologii języków programowania. To jest programista bez drugiego pilota około 2020 roku, pokolorowany. Wydaje mi się, że spotkałem go dziś rano na Central Square. A oto programista z copilotem w 2021 roku, prawda? Najwyraźniej więc bardzo szybko ewoluujemy jako gatunek programistów. Niestety, w obu przypadkach mamy do czynienia z mężczyznami. Przepraszam za to. Więc ile osób tutaj korzystało z copilota lub jednego z jemu podobnych, jeśli chodzi o pomoc w pisaniu kodu? Nie wstydź się. Wiem, że myślisz sobie, kto tu jest moim profesorem? Cholera. W porządku, więc copilot, jeśli go nie używałeś, jest kompletnym zmieniaczem gier pod względem tego, jak prawdziwi programiści piszą kod. Tak, jest to również ogromny impuls dla studentów, którzy chcą skutecznie skrócić swoją pracę domową, przyspieszyć jej wykonanie. Ale to jest dla kogoś pracującego w branży, piszącego kod każdego dnia, jeśli nie mam drugiego pilota, czuję się absolutnie nagi. Byłem tutaj w samolocie. Pisałem kod. Wi-Fi nie było wystarczająco szybkie. Wpisałem więc pół linijki kodu i czekałem, aż copilot dokończy go za mnie, jak zawsze. Ale zwykle dzieje się to w mniej niż sekundę. Tym razem trwało to tak długo. Powiedziałem, cholera. Chyba będę musiał napisać to sam, tak jak rok temu. Copilot jest niesamowity z kilku powodów. Myślę, że jedną z rzeczy, których ludzie w pełni nie doceniają, jest to, że utrzymuje cię w strefie pisania kodu. Kiedyś było tak, że za każdym razem, gdy trafiałem na małą przeszkodę, myślałem: o cholera. Nie pamiętam składni, jak odwrócić listę w dowolnym języku, w którym pracuję. Cholera. Cóż, wiem gdzie znaleźć odpowiedź. Po prostu ją wygoogluję. Jest gdzieś na Stack Overflow. Idę więc, googluję i znajduję odpowiedź. Prawdopodobnie nie jest to bezpośrednia odpowiedź. Muszę więc trochę poczytać artykuł i poskładać go w całość. O tak, to jest fragment, którego szukałem. A co robię 45 minut później? Jestem gdzieś na Reddicie. Wiesz, zszedłem do szczurzej nory surfowania po Internecie. Wyszedłem ze strefy pisania kodu. Myślę, że dzięki temu ludzie są o wiele bardziej produktywni, do tego stopnia, że nakazaliśmy każdemu programiście w naszej firmie korzystanie z Copilot. Jeśli ktoś nie używa Copilota, zostanie zwolniony. Cóż, nie powiedziałem tego, ale taka jest idea. Wiele osób ganiło lub krytykowało Copilota za to, że jest trochę głupi. To nie jest tak, że jest po prostu szkolony na rzeczach znalezionych w Internecie na GitHub i zadaniach domowych. Jak dobry może być? Jest niesamowicie dobry. Nie tylko papuguje rzeczy, które widział gdzie indziej. Interpretuje twój program i twoje intencje. Patrzy na inne części kodu, aby zrozumieć, co możesz zrobić dalej. Rozumie struktury danych. To nie tylko patrzenie na małe okno kontekstowe w bieżącym pliku, który edytujesz. To szukanie w innych miejscach kodu czegoś, co może być istotne. Jedyną rzeczą, która powstrzymuje Copilota przed staniem się w tym naprawdę, naprawdę, naprawdę dobrym, jest po prostu więcej danych i więcej obliczeń. I zgadnij co? Mamy obu tych rzeczy pod dostatkiem. Nic nie powstrzyma Copilota przed osiągnięciem niewiarygodnej wydajności w miarę upływu czasu. Oto kolejny podobny przypadek użycia. To nie jest Copilot. To jest ChatGPT, który na pewno wszyscy znamy. Ale jeśli próbujesz dowiedzieć się, jak coś zrobić - a w tym przypadku używałem DeepGram Python SDK do transkrypcji plików audio do tego podcastu, o którym wspomniałem wcześniej. Mógłbym spędzić 15, 20 minut czytając ich dokumentację, znajdując przykładowy kod w Internecie, postępując zgodnie z samouczkiem lub, ponieważ wszyscy jesteśmy tacy - programiści są niesamowicie leniwi - po prostu powiedzieć, hej, słuchaj, próbuję zrobić tę rzecz. Czy możesz po prostu dać mi kod, którego potrzebuję? I on to robi. Copilot to nie tylko rozumienie zadań domowych. ChatGPT to nie tylko rozumienie zadań domowych. Rozumie API i SDK innych osób, biblioteki programistyczne, abstrakcje, najlepsze praktyki i błędy, które mogą się pojawić. To znaczy, ma naprawdę dużą wiedzę. A więc przy bardzo niewielkim wysiłku mogę po prostu wyciąć i wkleić ten kod bezpośrednio do mojego programu i zająć się swoim życiem. Shel Silverstein, który napisał A Light in the Attic - to jest coś, książka z poezją dla dzieci, którą czytałem, gdy byłem dzieckiem. Widziałem to na Reddicie kilka dni temu. Całkowicie to przewidział. Jest rok 1981. Maszyna do odrabiania prac domowych, najdoskonalsze urządzenie, jakie kiedykolwiek widziano. Wystarczy wrzucić pracę domową, a następnie wrzucić dziesięciocentówkę, nacisnąć przełącznik, a za 10 sekund praca domowa wyjdzie, szybka i czysta. Oto 9 plus 4, a odpowiedź to 3. 3? O ja. Chyba nie jest tak idealnie, jak myślałem. Dokładnie. Kosztuje grosze, zajmuje około 10 sekund. Zgadłem, że odpowiedź jest błędna. Z tym właśnie mamy dziś do czynienia. Przy okazji, i to jest zupełny margines, ale nie mogę się powstrzymać, kiedy wspomniałem o Shel Silverstein, jeśli nie wiesz, jak wyglądał, to była okładka, zdjęcie na obwolucie jednej z jego pierwszych książek. Uwielbiam tego faceta. Autor książek poetyckich dla dzieci z lat 70-tych. I tak właśnie wyglądał. Niesamowite. W porządku. Więc teraz chcę porozmawiać o tym, że skoro technologia AI staje się tak dobra, to co stanie się z naszą branżą? Co to oznacza dla nas wszystkich, którzy mogą w przyszłości szukać pracy w tej branży i oczekiwać, że otrzymają te duże, tłuste wypłaty i dotacje do opcji na akcje oraz kupią Tesle lub cokolwiek innego, czego się spodziewamy? Ile więc kosztuje zastąpienie jednego ludzkiego programisty sztuczną inteligencją? Cóż, policzyłem. Powiedzmy więc, że typowe wynagrodzenie inżyniera oprogramowania w Dolinie Krzemowej lub Seattle wynosi około 220 000 USD rocznie. To tylko pensja podstawowa. Nie obejmuje świadczeń. Nie obejmuje pakietów kapitałowych. Nie obejmuje darmowego lunchu w kręgielni i tym podobnych rzeczy. Załóżmy więc, że te rzeczy kosztują 92 000 USD rocznie. Jest to, ponownie, nieco konserwatywne założenie. Zatem całkowity koszt dla pracodawcy wynosi około 300 000 USD, 312 000 USD za jeden SWE. Ile jest dni roboczych w roku? Około 260. Zatrudnienie pracownika jako SWE w jednej z tych firm kosztuje więc 1200 USD dziennie. Wystarczająco uczciwie? OK, więc policzmy. Jak myślisz, ile linii kodu przeciętny programista sprawdza w bazie kodu każdego dnia? Mam na myśli sfinalizowane, przetestowane, sprawdzone i zatwierdzone linie kodu. Większość z nas, którzy pracują w branży, wie, że mediana wynosi zero, ponieważ jest tak wiele dni, w których czekasz na kogoś innego lub jesteś na spotkaniach przez cały dzień. Nic nie zrobiłeś. Nie sprawdziłeś tego. Ale bądźmy hojni i powiedzmy, że jest ich około 100. Wiem, że 100 nie brzmi jak dużo. Ludzie mówią, ale ja programowałem cały dzień. Tak, ale 90% twojego kodu zostało wyrzucone lub ktoś go sprawdził i powiedział, że nie jest dobry. Trzeba go napisać od nowa. Próbowałeś dowiedzieć się, co zrobić. Odświeżałeś go. Tak więc ostateczny wynik to około 100 linii kodu dziennie. To jest ostateczny wynik. Ile tokenów modelu GPT-3? Mniej więcej 10 tokenów na linię. A koszt GPT-3... właściwie, to jest prawdopodobnie trochę nieaktualne. Ale w czasie, gdy robiłem ten slajd, było to 0,02 USD za 1000 tokenów. Jeśli więc policzyć, to całkowity koszt produkcji jednego ludzkiego programisty na GPT-3 wynosi 0,12 USD. Jest to współczynnik 10 000. 
 
 
 To powinno nas wszystkich przestraszyć. Sugeruje to potencjalnie bardzo dużą zmianę w naszej branży. Nie sądzę, byśmy mogli to zignorować i po prostu spisać na straty, mówiąc: cóż, sztuczna inteligencja nie jest dziś zbyt dobra, więc nie będzie dobra za pięć lat. To radykalnie zmienia sposób, w jaki o tym myślimy. Jedynym powodem, dla którego programistom płaci się tak dużo, jest to, że aby być w tym dobrym, potrzeba wielu lat edukacji, szkoleń, wiedzy i specjalizacji. Ale nie ma powodu, dla którego muszę zatrudniać do tego super inteligentnego studenta z Harvardu, jeśli mogę sprawić, by ChatGPT wykonał większość pracy za mnie, a człowiek ją wpisał. Jest wiele innych zalet zatrudniania robotów zamiast ludzi, prawda? Roboty nie będą robić przerw. Roboty nie oczekują dziś darmowych lunchów i masażu na miejscu. To może się zmienić. Robot potrzebuje tyle samo czasu, aby wygenerować swój kod, niezależnie od tego, czy jest to wstępny dowód koncepcji, czy ostateczny kod gotowy do produkcji. Kiedy idziesz jako PM do swojego zespołu inżynierów i mówisz: OK, zespole, jest was tu ośmiu. Musimy wysłać stronę rozliczeniową. Jak szybko możemy to zrobić? Spędzisz co najmniej półtorej godziny na rozmowie, no wiesz, jeśli zrobimy to szybko i brudno, możemy to zrobić w ciągu trzech tygodni. A jeśli to ma być gotowe do produkcji, daj nam 12. Albo możesz iść do przysłowiowej maszyny do odrabiania lekcji, nacisnąć przycisk i mieć kod już teraz, prawda? A druga sprawa jest taka, że owszem, robot popełnia błędy. Ale te błędy mogą zdarzyć się niewiarygodnie szybko do poziomu prędkości, w którym iteracja, iteracja, iteracja, iteracja, iteracja, iteracja, iteracja jest całkowicie w porządku. Możesz powiedzieć robotowi, wiesz co? To wszystko, 5000 plików źródłowych, 20 000 linii kodu, cokolwiek to jest, wywal to, zacznij od nowa. Bum. Pięć sekund później masz zupełnie nową wersję. Spróbuj tego z żywym zespołem inżynierów. Myślę więc, że jest to coś, co naprawdę musimy potraktować poważnie. Nie sądzę, że to tylko - przesadzam dla efektu - ale branża się zmieni. Naturalnym pytaniem jest więc, co się stanie, gdy odetniemy ludzi od pętli? Jak tworzymy oprogramowanie? Jak dostarczamy produkty? Znalazłem ten film na - myślę, że to strona Microsoftu - zatytułowany "What Do Product Managers Do?". "Myślę, że był to trochę niezamierzony żart, ponieważ jako inżynierowie często zastanawiamy się, co robią menedżerowie produktu? Ale jeśli wyobrazisz sobie, jak może wyglądać zespół programistyczny przyszłości, myślę, że jest to jedno z bardzo prawdopodobnych podejść, które polega na tym, że masz menedżera produktu - prawdopodobnie nadal jest to człowiek - biorącego wymagania biznesowe i produktowe, wymagania użytkowników i tłumaczącego je na jakąś formę, prawdopodobnie angielski, może trochę techniczny angielski, który następnie możesz dostarczyć sztucznej inteligencji, armii generatorów kodu sztucznej inteligencji. Generatory kodu AI dają ci całą masę kodu i prawdopodobnie jeszcze przez jakiś czas ludzie będą czytać i przeglądać kod, aby upewnić się, że robi to, co powinien. Teraz to czytanie różni się nieco od tego, co mamy dzisiaj. Dzisiaj, kiedy sprawdzamy kod, jeśli mam innego inżyniera w moim zespole piszącego kod i sprawdzam go, standardową praktyką w branży jest wzajemne sprawdzanie kodu. Nie tylko sprawdzamy kod. Czytamy nawzajem swój kod. Dodajemy do niego szczegółowe komentarze. Sugerujemy ulepszenia, poprawki, wyjaśnienia, komentarze, dokumentację. W tym przypadku nie jest absolutnie konieczne, aby ten kod mógł być utrzymywany przez człowieka. Myślę, że przez jakiś czas będziemy tego chcieli. Większość ludzi nie będzie czuła się komfortowo, pozwalając robotom wykonywać całe kodowanie. Ale w pewnym momencie, tak długo, jak mogę przekonać samego siebie, że kod robi to, co powinien, nie obchodzi mnie, jak bardzo jest niechlujny. Nie obchodzi mnie jego struktura. Nie obchodzi mnie, jak bardzo jest on wielokrotnego użytku. Wszystkie te czynniki wynikają tylko z tego, że biedni ludzie muszą się z tym zmagać. Och, to musi być modułowe. Musimy mieć granice abstrakcji. Wszystkie te rzeczy - informatyka na poziomie drugiego roku, prawda? Dlaczego? Ze względu na biednych ludzi, którzy muszą radzić sobie z tą złożoną bazą kodu. Ale jeśli to roboty go generują, a my nie musimy go utrzymywać w konwencjonalny sposób, to dlaczego po prostu nie wygenerować potrzebnego kodu? Nie ma znaczenia, czy jest on zduplikowany, powtarzalny, modułowy czy ładnie wyabstrahowany. Nie ma znaczenia. Wykonuje swoją pracę. Jedną z moich hipotez dotyczących tego, dlaczego wszyscy szaleją na punkcie czatu GPT, jest to, że w przeciwieństwie do innych branż, ta rewolucja wydawała się nastąpić z dnia na dzień. O ile nie jesteś profesorem sztucznej inteligencji i naprawdę śledzisz literaturę od lat, dla większości z nas, w tym dla mnie, wydawało się, że przeszliśmy od sztucznej inteligencji, która była trochę kiepska, do sztucznej inteligencji, która była niesamowita, dosłownie z dnia na dzień. Używając analogii, byłoby to tak, jakby dziedzina grafiki komputerowej przeszła od Ponga do Red Dead Redemption 2 w ciągu około trzech miesięcy. Gdyby tak się stało, ludziom eksplodowałyby głowy. Ale tak się nie stało w grafice. W grafice dojście do tego punktu zajęło dekady. I każdy mógł zobaczyć, jak stopniowo staje się coraz lepsza i lepsza. Pamiętam, kiedy wyszło Toy Story. To był pierwszy film CG. Umysły ludzi po prostu się rozpłynęły, gdy to oglądali. Byli jak, whoa. A teraz oglądamy to i po prostu idziemy, tak, to jest słodkie. Mógłbym to wyrenderować na moim laptopie i porysować lub cokolwiek innego. Inną rzeczą, która moim zdaniem wydarzyła się w tej dziedzinie, która jest interesująca, i zachodzi duża zmiana społeczna, jest dialog wokół naszych oczekiwań co do tego, co sztuczna inteligencja może osiągnąć. W 1972 roku Hubert Dreyfus napisał książkę What Computers Can't Do. Było to u zarania ery komputerów osobistych. W popularnej prasie pojawiło się wiele dyskusji na temat tego rodzaju straszenia sztuczną inteligencją. Pojawiły się filmy takie jak Gry wojenne. Czy ktoś to pamięta? Myślę, że "Gry wojenne" - nawiasem mówiąc, to właśnie dzięki temu filmowi zostałem informatykiem. Chciałem być Matthew Broderickiem w tym pokoju z tymi wszystkimi monitorami i moim analogowym modemem i włamywać się do szkolnego komputera. Taki byłem jako dzieciak. Myślę, że w tamtym czasie wiele osób mówiło: no cóż, poczekaj chwilę. Komputery są z gruntu głupie, nie potrafią robić takich rzeczy i nigdy tego nie zrobią. I to była teza tej książki. I myślę, że był to rodzaj konsensusu. Uspokoiliśmy się trochę w kwestii technologii. Wszyscy zdaliśmy sobie sprawę, że Visicalc nie pozbawi mnie pracy. Ale teraz szybko do przodu 2014. Gorąco polecam książkę Nicka Bostroma zatytułowaną Superinteligencja, jeśli jeszcze jej nie czytałeś. Jest to książka, która w ogromnej ilości szczegółów zmaga się z filozoficznymi i moralnymi pytaniami o to, jak ludzkie społeczeństwo reaguje na sztuczną inteligencję, która jest bardziej inteligentna niż ludzie? Wiem, że wokół tego tematu powstało wiele filmów science-fiction, ale jest to bardzo poważna praca akademicka na temat tego, co to oznacza dla naszego społeczeństwa, jeśli mamy SI, która jest mądrzejsza od nas? Ludzie traktują to dziś bardzo poważnie. Myślę więc, że chodzi mi o to, że dialog, który prowadzimy w całym społeczeństwie, zmienił się z AI jako zabawki na AI, która może faktycznie zniszczyć społeczeństwo. Porozmawiajmy więc szybko o przyszłości, ewolucji programowania, tak jak ja ją widzę. U zarania dziejów ludzie bezpośrednio pisali instrukcje maszynowe i wprowadzali je za pomocą przełączników i tym podobnych rzeczy. Było to zanim jeszcze wynaleziono programowanie w konwencjonalnym sensie. Następnie mieliśmy wczesną prehistorię, a ludzie zaczęli pisać programy w językach wyższego poziomu. A potem mieliśmy początek XX wieku, pisanie programów w językach wyższego poziomu. To Bjorn Strauss-Strupp, który wynalazł język C . W dzisiejszych czasach mamy świat, w którym ludzie piszą swój kod, ale są mocno wspomagani przez sztuczną inteligencję. I mogą uciec od rzeczy takich jak, cóż, po prostu napiszę komentarz, a sztuczna inteligencja napisze kod za mnie. Twierdzę jednak, że przyszłością jest całkowite pominięcie etapu programowania. Myślę, że wiele osób, które przeczytały mój artykuł na ten temat w CACM na początku tego roku, błędnie zinterpretowało go jako stwierdzenie, że sztuczna inteligencja napisze za nas kod. Dlatego programiści nie powinni istnieć. Wcale tak nie twierdzę. W rzeczywistości mówię coś znacznie gorszego, a mianowicie, że w ogóle nie będziesz musiał mieć programów. Po prostu mówisz modelowi języka, czego chcesz, a on bezpośrednio oblicza wynik. Nie ma kroku programu. I myślę, że to otwiera - jest to interesujące wyzwanie dla naszej dziedziny, ale myślę, że otwiera to ogromne możliwości. Ponieważ teraz pytanie brzmi: jak skutecznie nauczyć te modele, co mają robić? Wracając do mojego wcześniejszego przykładu z koniecznością używania słów NIE wielkimi literami, jakie są najlepsze praktyki? A poza najlepszymi praktykami, czy możemy przekształcić to z mrocznej sztuki w naukę, w dyscyplinę inżynieryjną? Ludzie mówili o inżynierii podpowiedzi. Myślę, że to z przymrużeniem oka. To tak naprawdę nie jest inżynieria. Tak naprawdę to jeszcze nic takiego. Ale może być w przyszłości, jeśli zrobimy to dobrze. Jedną z rzeczy, które ludzie często mówią o tych modelach, jest to, że nie ma możliwości, aby zrobiły coś interesującego lub kreatywnego, ponieważ wszystko, co robią, to automatyczne uzupełnianie na podstawie dużych zbiorów tekstu, które widziały i na których zostały przeszkolone. Jestem innego zdania. Oczywiście nie wiemy, co tak naprawdę dzieje się wewnątrz tych modeli. Ale jeśli poprosisz duży model językowy o podjęcie złożonego problemu i efektywne wykonanie obliczeń, czyli manipulowanie modelem świata w jego umyśle, w tym przypadku, wymyśliłem prosty problem. Powiedziałem, że mam trzy stosy kart, czerwone, zielone i niebieskie. Wszystkie są potasowane w następujący sposób. Powiedz mi, jak ułożyć je w trzy stosy, jeden czerwony, jeden zielony, jeden niebieski. Prosty problem, prawda? Dziecko mogłoby to zrobić. Kluczową frazą było tutaj, jak odkryto niedawno, kilka miesięcy temu, wypowiedzenie słów, magicznych słów, pomyślmy krok po kroku. Jeśli powiesz to modelowi, w jakiś sposób spowoduje to przejście do trybu obliczeniowego. Nie będzie już tylko papugował odpowiedzi. W rzeczywistości powie: OK, cóż, muszę wyjaśnić każdą z moich instrukcji. I tak to robi, absolutnie to robi. A fakt, że jest w stanie manipulować pewnego rodzaju wewnętrznym modelem tego stosu kart, który opisałem i powiedzieć mi dokładnie, jak to będzie działać i jest poprawne, jest dla mnie fascynujący. Nie jest trudno się pomylić. Jest wiele miejsc, w których można mu sprawić problem, a on natychmiast się przewróci i powie: przepraszam. Zwróci fałszywe wyniki. Więc pytanie brzmi: dlaczego? Co robimy w tym przypadku? Jak zrozumieć ograniczenia tych modeli? Myślę więc, że z czasem dojdziemy do miejsca, w którym programowanie zostanie zastąpione nauczaniem tych modeli nowych umiejętności. I nauczenie ich, jak łączyć się z interfejsami API, pobierać dane z baz danych i przekształcać dane oraz jak wchodzić w interakcje z oprogramowaniem przeznaczonym dla ludzi. Stanie się to całą dyscypliną. Jednym ze sposobów myślenia o tym, dokąd to może zmierzać, jest coś, co lubię nazywać komputerem języka naturalnego. Tak więc architektura von Neumanna służyła nam dobrze przez wiele dziesięcioleci. To jest nowa architektura. Nowa architektura polega na dostarczeniu programu w języku naturalnym. Używasz modelu językowego, który następnie może wywoływać zewnętrzne systemy i oprogramowanie jako urządzenia peryferyjne. Może przechowywać wyniki i zadania w swojej pamięci, wspomagane przez takie rzeczy jak wektorowe bazy danych i tak dalej. I może działać autonomicznie w cyklu, wykonując ten program, tworząc zadania, uzyskując dostęp do zewnętrznych źródeł danych, generując nową wiedzę i tak dalej. Mnóstwo ludzi i my również budujemy rzeczy, które skutecznie działają w ten sposób. Myślę, że jest to rodzaj nowej architektury obliczeniowej, którą widzimy obecnie. I nie sądzę, by ktokolwiek miał rację. Nikt nie ma tego dobrze. Ale widzimy jej zalążki. To, co mamy dzisiaj, jest czymś w rodzaju odpowiednika, nie wiem, PDP-11 lub Apple One tej architektury. Jestem więc prawnie upoważniony do zaprezentowania mojego startupu. Spędzę więc trochę czasu, nie za dużo, mówiąc o tym, co robimy w Fixie, ponieważ jest to związane z tym. W rzeczywistości jest to istotne dla tego, jak myślimy o przyszłości tworzenia oprogramowania. Tak więc to, co robimy w Fixie, to podczas gdy mamy długoterminową wizję komputera języka naturalnego, pytanie brzmi: jako startup na wczesnym etapie, który musi zdobyć - zdobyć trochę biznesu, zdobyć klientów, uzyskać pewną przyczepność, zacząć demonstrować, że ta rzecz może zarabiać pieniądze dla naszych inwestorów, co budujemy dzisiaj? Co możemy zbudować dzisiaj? To, na czym skupiamy się w Fixie, to skuteczne ułatwienie zespołom programistów przejścia od stosu danych, które mają, do chatbota na żywo osadzonego na stronie internetowej, który rozumie wszystkie te dane i może odpowiadać na pytania i podejmować działania, wywoływać interfejsy API, robić wszystkie wymyślne rzeczy, które chcesz. Jest to więc coś w rodzaju w pełni niestandardowego czatu GPT dla twojej aplikacji dla twojej witryny dla twoich danych. To właśnie robimy w Fixie. Możesz zalogować się na naszej stronie internetowej, zarejestrować się, założyć konto, to nic nie kosztuje, wypróbować, wysłać mi opinię, zganić mnie, cokolwiek. Chciałbym usłyszeć, co ludzie budują za pomocą tego narzędzia. Jedną z rzeczy, które odkryliśmy, jest to, że naprawdę ważne jest, aby wymyślić dobrą abstrakcję programowania, która łączy język naturalny i język programowania. Ponieważ obecnie mamy do czynienia z zabawnymi sytuacjami, w których podpowiedź w języku naturalnym znajduje się w pliku tekstowym, a program w języku programowania znajduje się tutaj. Odnoszą się one do siebie w jakiś dziwny sposób, ale nie są zintegrowane. Jest to bardzo nieporęczne i kłopotliwe. Wymyśliliśmy więc framework o nazwie AI. jsx, który, jeśli znasz Reacta, jest w zasadzie Reactem do budowania aplikacji opartych na LLM. Jedną z interesujących rzeczy w AI. jsx jest to, że robienie takich rzeczy jak komponowanie operacji jest bardzo naturalną rzeczą. Oto przykład, w którym na górze mam funkcję o nazwie kid safe. Pomysł z kid safe polega na tym, że bierzesz cokolwiek ci dano i przepisujesz to tak, aby było w porządku dla dzieci. Ponownie, rzucam wyzwanie każdemu, kto napisze algorytm do tego. Proszę, powiedz mi, jaki to algorytm. Ale modele językowe nie mają z tym problemu. Wykonują niesamowicie dobrą robotę. Więc jeśli wezmę komponent bezpieczny dla dzieci, to po prostu przepisuje wiadomość użytkownika tak, aby była bezpieczna dla dzieci. A potem ten komponent dzieci, mogę zawinąć wszystko w blok bezpieczny dla dzieci i wiem, że będzie to bezpieczne dla dzieci. Otrzymujemy więc przyjemną programistyczną kompozycję możliwości. Możesz ponownie użyć tych operatorów. Można je łączyć w interesujący sposób. Ci z was, którzy wiedzą, czym jest rozszerzone generowanie wyszukiwania, mają na myśli pobieranie danych ze źródła danych, przekazywanie ich do modelu językowego i proszenie go o udzielenie odpowiedzi na pytania dotyczące tych danych. To bardzo złożony proces. Składa się z wielu elementów. Jest wiele kroków. Jest dużo dostrajania. W AI.jsx można to zrobić w 10 linijkach kodu. Mówisz, użyj tych informacji. Wyszukaj dane z korpusu. Oto zapytanie. Skończyłeś. I wreszcie, kiedy skończysz budować swoją aplikację AI.jsx, ponieważ jest to tylko React, możesz upuścić ją na swojej stronie internetowej jako komponent React. W ten sposób otrzymujesz okno czatu, interfejs użytkownika i wszystkie te fajne rzeczy. Tak. Więc masz coś. Przepraszam, nie wiedziałem, że jest animacja, ale tak to wygląda. Chcę pokazać ci naprawdę krótkie demo czegoś, co stworzyliśmy, aby podkreślić wszystkie te elementy, które się ze sobą łączą. Jedną z rzeczy, nad którymi spędziliśmy dużo czasu, jest to, jak sprawić, by interakcje z modelem językowym były tak szybkie, naturalne i interaktywne, jak to tylko możliwe. Odkryliśmy również, że w wielu aplikacjach ludzie chcą komunikować się głosowo, a nie wpisywać tekst. Stworzyliśmy więc to demo. Wyobraź sobie, że jesteś przy okienku drive-thru naszej restauracji z pączkami, którą nazywamy Dr. Donut. A to miało na celu podzielenie różnicy. Gdybym powiedział Krispy Kreme, wszyscy w Bostonie byliby na mnie źli. Gdybym powiedział Dunkin' Donuts, zachodnie wybrzeże nie miałoby pojęcia, co to jest. Więc Dr. Donut, oto menu Dr. Donut. I Justin, nie zamierzam teraz robić tego jako demonstracji na żywo. Mógłbym, ale nie jestem aż tak odważny. Więc pokażę ci wideo, bardzo krótkie wideo, jak to wygląda osobiście. Witamy w Dr. Donut, domu najlepszych pączków w mieście. W czym mogę pomóc? Tak. Czy mógłbym dostać dwa pączki z mrożoną przyprawą dyniową? Jasne. Dodałem dwa pączki z przyprawą dyniową do zamówienia. W czym jeszcze mogę pomóc? Jaka jest najlepsza kawa? Nasza kawa z przyprawą dyniową jest popularnym wyborem w tym sezonie. A nasze karmelowe macchiato jest ulubione przez cały rok. Którą byś wolał? Tak, wybierzmy dwie kawy macchiato. Świetnie. Dodałem dwie karmelowe macchiato do zamówienia. Czy mogę zamówić coś jeszcze? Co sądzisz o dużych modelach językowych? Proszę pana, to jest Dr. Donut. W takim razie tylko pączki i kawę. Jasne. Zamówienie to dwa mrożone pączki z przyprawą dyniową i dwie karmelowe macchiato. Łączna kwota to 9. 56 dolarów. Proszę do następnego okienka. Zdaję sobie sprawę, że samo w sobie może to nie wydawać się imponujące. Ale gdybyś spróbował to zbudować, używając tylko gotowych rzeczy, po prostu chwytając otwartą sztuczną inteligencję, klucze API, uzyskując model mowy, uzyskując model głosu, uzyskując wszystkie te rzeczy, wszystkie te elementy razem, wektorową bazę danych i wszystko to, byłoby to potwornie powolne. Widzieliśmy, jak sądzę, OpenAI wydało swoje małe demo głosowe czatu GPT. Mówią "cześć", a odpowiedź zajmuje od czterech do pięciu sekund. Tak więc wiele pracy trzeba włożyć w usprawnienie procesu przekazywania danych między tymi wszystkimi różnymi systemami i przekazywania ich z powrotem, aby osiągnąć ten poziom wydajności. I faktycznie, odkąd nagraliśmy ten film, udało nam się obniżyć wydajność jeszcze bardziej. Sprawy zaczynają więc wyglądać bardzo obiecująco, jeśli chodzi o interakcję głosową w czasie rzeczywistym z tymi rzeczami. OK, więc teraz wrócę do regularnie zaplanowanego wykładu. Ostatnią rzeczą, którą chcę powiedzieć, jest to, że jak już mówiłem, myślę, że nadszedł czas, abyśmy naprawdę pomyśleli o tym, jak rozwijamy tę dziedzinę w świetle tej technologii. Nie sądzę, by było na to za wcześnie. Myślę, że każdy, kto dziś uczy informatyki, już to widzi. Na zajęciach studenci korzystają z ChatGPT i Copilot. Wiele się uczą dzięki tym narzędziom. Pozwalają one na poziomy automatyzacji, których nie mogli osiągnąć jeszcze kilka lat temu. W przeszłości mieliśmy do czynienia z ewolucją w różnych dyscyplinach inżynieryjnych i naukowych, prawda? Kiedyś suwak był sposobem na wykonywanie obliczeń. Każdy jej potrzebował. Każdy musiał wiedzieć, jak go używać. Było to krytyczne narzędzie dla każdej osoby w dowolnej dyscyplinie inżynieryjnej. Nie widziałem suwaka od lat. Właściwie to ją mam. Kupiłem ją w serwisie eBay jako swego rodzaju relikt, ale jej nie używałem. Zastanawiam się więc, czy nasza koncepcja informatyki, ten obraz tutaj, również będzie w pewnym momencie postrzegana jako relikt przeszłości, ten pomysł, że istnieje człowiek. Płacą im dużo pieniędzy. Piszą kod. W ten sposób zmuszamy komputery do robienia rzeczy za nas. Nie jestem pewien. Oto jeden z wiarygodnych pomysłów. Nie wszyscy się z tym zgodzą, ale być może z czasem dziedzina informatyki wygląda trochę tak, jak dziedzina EE w odniesieniu do dzisiejszej informatyki. Informatyka wyewoluowała z matematyki i EE. Wcześniej nie istniała. Potem pojawiła się nowa technologia i stopniowo informatyka wyłoniła się z tych dwóch dyscyplin. EE nie zniknęła. Jak rozumiem, matematyka też nie zniknęła. Ale jak myślimy o tym związku? EE jest bardzo krytyczna. Polegamy na niej cały czas. Ale czy wszyscy muszą ją rozumieć? Nie. To bardziej wyspecjalizowana dyscyplina. Jeśli więc myślimy o przyszłości, w której ludzie tworzący oprogramowanie nie piszą programów w konwencjonalny sposób, w jaki robimy to dzisiaj, a zamiast tego zlecają sztucznej inteligencji wykonywanie ich poleceń, co to oznacza? I myślę, że jest w tym naprawdę obiecująca strona, która prawdopodobnie znacznie rozszerza dostęp do komputerów dla całej ludzkiej populacji. Dziś, gdybym pracował w banku w małym miasteczku w Etiopii, w miejscach, które odwiedziłem, i potrzebowałbym zbudować jakąś automatyzację dla czegoś, co robię w mojej pracy, powodzenia. Powodzenia w znalezieniu kogoś, kto mógłby napisać dla mnie kod, kto mógłby zrozumieć mój problem, kto mógłby go ze mną iterować, kto mógłby go dla mnie utrzymywać, kto mógłby go z czasem rozwijać. Powodzenia. Ale dzięki tej technologii, być może osoba, która nie ma żadnego formalnego wykształcenia w dziedzinie informatyki, ale rozumie, że ma te arkusze kalkulacyjne, ma te raporty i ma te rzeczy, które musi zrobić, może poprosić sztuczną inteligencję, aby po prostu to zrobiła. To niezwykle wzmacniające. Myślę, że wszyscy jako dziedzina powinniśmy do tego dążyć, do takiego poziomu dostępu do mocy obliczeniowej. Nie powinno to pozostawać w sferze kapłańskiej. W 1984 roku John Gage powiedział, że sieć jest komputerem. Było to słynne hasło używane przez Sun Microsystems. Nigdy do końca nie zrozumiałem jego znaczenia. Ale taka była idea. Sieć jest komputerem. Cóż, to jest moje nowe hasło. Model jest komputerem. Nie twierdzę więc, że nie ma tu żadnych wyzwań. Malowałem pewien różowy obraz, ponieważ uważam, że ważne jest, abyśmy zrozumieli nadchodzącą falę i zastanowili się, co to oznacza dla naszej dziedziny. Nie chcę przez to powiedzieć, że wszystkie problemy zostały rozwiązane. W żadnym wypadku. Największym brudnym sekretem w całej branży jest to, że nikt nie rozumie, jak działają modele językowe. Ani jedna osoba na tej planecie. I myślę, że gdybym miał tu Jeffa Deana lub Jeffa Hintona, myślę, że całkowicie zgodziliby się z tym stwierdzeniem. Idea rozumowania opartego na łańcuchu myślowym, pomysł, że udało mi się zmusić model językowy do wykonywania obliczeń za pomocą magicznej frazy, pomyślmy krok po kroku, została odkryta empirycznie. Nie zostało to wytrenowane w żadnym modelu. Nikt o tym nie wiedział. Była to ukryta zdolność tych modeli, na którą ktoś się natknął, napisał o niej artykuł i powiedział: hej, jeśli powiesz "myślmy krok po kroku", model zacznie wykonywać obliczenia. Whoa. To niesamowite. To niesamowite, że odkrywamy, że te rzeczy mogą wykonywać obliczenia. I być może plusem jest to, że wiele osób wyrażało konsternację, ale tak naprawdę programowanie jest do bani, prawda? Jest trochę upierdliwe. Jest frustrujące. Jest powolne. Mentalnie męczące. Może uda nam się dojść do miejsca, w którym po prostu pozwolimy robotom to robić, a sami zajmiemy się czymś innym. To by było na tyle. Dziękuję bardzo. [Zanim przejdziemy do pytań, nie wiem, jaki jest status pizzy. Przychodzimy na rozmowę, zostajemy na pizzę. Czy chcesz to zrobić teraz, czy chcesz najpierw zadać kilka pytań? Albo jak... Najpierw pytania, a potem zobaczymy, jak nam idzie. Brzmi dobrze. Pytania? Tak. W jaki sposób model sztucznej inteligencji mógłby zastąpić programistę i wygenerować kod, który działa, ale jest niezrozumiały dla człowieka, jak to przetestować? Ponieważ uważam, że jeśli programowanie jest do bani, pisanie przypadków testowych jest do bani 10 razy. Tak, to bardzo dobre pytanie. I myślę, że w ciągu najbliższych kilku lat zobaczymy, jak to się potoczy. Powtórzę pytanie. Dziękuję, Harry. Więc pytanie brzmiało: jeśli sztuczna inteligencja generuje kod, którego człowiek nie może zrozumieć, jak go przetestować? Skąd wiesz, że zrobił to dobrze? A pisanie testów jest naprawdę do bani. Pisanie testów jest często łatwiejsze niż pisanie logiki, którą testujesz. To jedna rzecz. Nie potrzebujesz tak dużej specjalizacji. Jeśli masz specyfikację tego, co program powinien robić, napisanie testu nierzadko jest dość prostą rzeczą do zrobienia. To o wiele łatwiejsze niż manipulowanie bazą danych i tworzenie infrastruktury. Po prostu piszesz testy. Obecnie trwają intensywne prace nad testami generowanymi przez sztuczną inteligencję. Teraz wszyscy powinniśmy być może śmiertelnie przerażeni pomysłem sztucznej inteligencji generującej nasz kod i piszącej testy. Więc gdzie mamy ludzi w pętli? Gdzie jest człowiek w tym procesie? To otwarte pytanie. Nie mam na nie dobrej odpowiedzi. Ale myślę, że ludzie zaczną - nawet jeśli będzie to niedoskonałe - pisać programy w C w 2023 roku. To powinno być przestępstwo federalne. Jeśli pomyślisz o tym, ile błędów w oprogramowaniu, bugów, awarii zagroziło ludziom, a nawet ich zabiło - nie zmyślam. To prawda - że ludzie zginęli z powodu błędów przepełnienia w programach C, wciąż potrzebujemy pewnej metodologii testowania, bezpieczeństwa i regulacji oraz zrozumienia, jak rzeczy działają. Nie można po prostu powiedzieć, że kod jest napisany, zrobiony i wydaje się spełniać swoje zadanie. Przetestowałem go dwa lub trzy razy. I wysłałem. Nie mówię więc, że powinniśmy wyrzucić wszystkie inne rzeczy. Ale musimy znaleźć sposób na wykorzystanie SI w efektywny sposób, jednocześnie myśląc o problemie bezpieczeństwa. I nie wiem. To dobre pytanie. Z tyłu. Jeśli to jest przyszłość, a my stoimy na początku podróży, jakie są główne kamienie milowe, które musimy osiągnąć, aby faktycznie dostać się do przyszłości? I jakie widzisz przeszkody techniczne, których nie możemy pokonać? Tak, więc pytanie brzmi: jeśli to jest początek przyszłości - a myślę, że z definicji tak jest, ale OK - i to jest przyszłość, którą sobie wyobrażam, jakie są kamienie milowe, aby się tam dostać? Jakie wyzwania techniczne musimy pokonać, by to osiągnąć? Jedną z interesujących rzeczy jest to, że bardzo liczę na to, że efektywne dodanie większej liczby tranzystorów do problemu sprawi, że te modele będą tysiące razy lepsze niż są obecnie. Myślę, że większość ludzi w branży zgodziłaby się, że jeśli rzucisz więcej tranzystorów i więcej danych na problem, otrzymasz znacznie, znacznie lepszy model. Myślę, że jednym z wyzwań jest to, jak zdobyć te wszystkie tranzystory? Ponieważ NVIDIA może wyprodukować tylko tyle. W tym obszarze toczy się wiele interesujących prac. Zamierzam przedstawić byłego studenta Harvardu, Gavina Uberti, który jest synem naszego CTO. Genialny facet. Kilka miesięcy temu przeprowadził się do San Francisco, aby założyć firmę zajmującą się budową chipów zaprojektowanych specjalnie do obsługi tych modeli. Pracował nad tym z Gu Yanhui i Davidem Brooksem. Jest więc nadzieja, że niestandardowy sprzęt może pomóc rozwiązać część tego problemu. Powiedziałbym, że większym i prawdopodobnie bardziej drażliwym i niepewnym problemem jest to, jak możemy rozumować o możliwościach tych modeli w formalny sposób? To znaczy, w jaki sposób możemy złożyć jakiekolwiek oświadczenie o poprawności modelu, gdy zostaniemy poproszeni o wykonanie określonego zadania? Teraz, zanim pójdziemy tą ścieżką zbyt daleko, myślę, że mamy naturalną ludzką tendencję do postrzegania modelu sztucznej inteligencji jako maszyny, która musi być zgodna z jakąś specyfikacją zapisaną gdzieś w podręczniku. A teraz mamy tę maszynę, ale nie ma instrukcji obsługi, więc jest jak w tym programie telewizyjnym The Greatest American Hero. Musimy wymyślić instrukcję. Musimy opracować instrukcję poprzez eksperymenty. Innym sposobem patrzenia na te rzeczy jest to, że jeśli myślisz o modelu sztucznej inteligencji jako o naprawdę, naprawdę inteligentnym studencie, którego właśnie zatrudniłeś jako stażystę w swojej firmie, masz pewien stopień wiary, że ta inteligentna osoba, z którą rozmawiałeś przez pół godziny, będzie w stanie wykonać rzeczy, o które ją poprosiłeś, wiernie, etycznie i poprawnie, niezależnie od tego, czy chodzi o napisanie raportu, przygotowanie prezentacji, korzystanie z faksu. Ale czy masz na to jakąkolwiek gwarancję? Czy mogę obiecać, że osoba, którą zatrudniłem, za każdym razem zrobi to poprawnie? Nie, prawda? A jednak ludzkie społeczeństwo kwitnie. Zmierzam więc do tego, że być może nasz sposób myślenia o tym problemie powinien przesunąć się bardziej w kierunku, w pewnym sensie, nauk społecznych i systemów, które pozwolą nam zrozumieć, w jaki sposób SI działają w naszym społeczeństwie, zamiast traktować je jak maszyny, których poprawność musimy udowodnić. Tak? Czy można więc zbudować model wyjaśniający [INAUDIBLE], czy też modele mogą próbować wyjaśnić każdy z nich? Tak, więc pytanie brzmi: czy jeden model może skutecznie wyjaśnić inny model? Ponieważ powiedziałeś, że nikt tego nie rozumie. Tak, nikt tego nie rozumie. To interesujący pomysł. Nie brałem go wcześniej pod uwagę. Myślę, że przeprowadzono na ten temat interesujące badania. Myślę, że cała dziedzina wyjaśnialności i obserwowalności modeli językowych, staramy się zrozumieć te modele w taki sam sposób, w jaki staramy się zrozumieć ludzki mózg. Widziałem ostatnio badania, w których mówiono: hej, spójrz co się stało. Wzięliśmy ten duży model językowy i wyizolowaliśmy neuron, który wykonuje tę funkcję. Ludzie będą publikować artykuły przyrodnicze na ten temat, prawda? To szalone, ponieważ jest to artefakt, który w pewnym sensie stworzyliśmy, ale nie do końca, prawda? Został wytrenowany. Więc pytanie brzmi, czy język - czy jeden model może sprawdzać, badać, sondować, rozumieć i dawać nam pewne zrozumienie innego modelu? To dobry pomysł. Nie mam pojęcia. To dobre pytanie. [Jestem po prostu kiepskim specem od systemów. Więc ostatnią rzeczą, jaką zamierzam zrobić przed grupą informatyków z Harvardu, jest mówienie czegokolwiek o teorii. Stuart. Jesteś więc bardzo optymistycznie nastawiony do większej ilości danych i obwodów. Pomyślałem, że ChatGPT ma większość dostępu do większości Internetu i myśli 8 miliardów ludzi, co daje malejące zyski przy większej wiedzy, a nie wyprodukujemy kolejnych 8 miliardów ludzi, a przejście z 8 bitów na 4 bity w sposobie przetwarzania rzeczy dałoby nam stałe współczynniki. Jak uzyskać o wiele więcej danych i o wiele więcej obliczeń? Tak, obliczenia, o których mówiłem wcześniej - więc pytanie brzmi, jeśli wierzysz w prawo skalowania, że więcej obwodów, więcej danych daje nam lepsze modele, cóż, czy nie ma malejących zwrotów w czasie? Ponieważ na świecie jest tylko tyle danych i tylko tyle tranzystorów. Poruszyłem więc, mam nadzieję, kilka kwestii dotyczących tego, jak możemy rozwiązać problem tranzystorów w przyszłości. Problem danych jest bardzo realny. Nie wiem, jakie są najnowsze rozważania na temat tego, o ile więcej danych potrzeba do, powiedzmy, 10-krotnego zwiększenia obecnej generacji modeli. To jest w pewnym sensie pytanie. Czy potrzebuję 10x więcej danych, czy nie? Ponieważ wszystko zależy od reżimu treningowego i malejących zysków z danych. Jedną rzeczą, którą chcę podkreślić, jest to, że uważam, że Chachi, BT i przyjaciele spojrzeli tylko na wierzchołek góry lodowej ilości danych wytwarzanych przez ludzkość. Jest to wierzchołek góry lodowej. Na świecie istnieje ogromna ilość wiedzy, zarówno w formie cyfrowej, jak i analogowej, do której te modele nigdy nie miały dostępu. Więc jedną z rzeczy, które zauważysz, podobnie jak Chachi, BT i wszystko inne, jest mocno, mocno, mocno nastawione na tekst, który jest w Internecie. Kto stworzył tekst, który był w Internecie? Głównie anglojęzyczni ludzie w zachodnim świecie. I oczywiście jest to zmiana, która ma miejsce teraz, ponieważ przeniesie się bardziej do Azji i innych krajów oraz innych języków. Ale jest tego ogromna ilość i jest to ogromna skarbnica, której nigdy nie widziano. Widział tylko publicznie dostępne dane internetowe. Nasi klienci i inne firmy działające w tej przestrzeni współpracują z firmami, które mają ogromne ilości danych, które absolutnie nie są publiczne, a które modele językowe mogłyby wykorzystać do lepszego zrozumienia i wykonywania większej liczby zadań. Jestem więc przekonany, że być może zeskrobaliśmy powierzchnię dostępnych danych, ale jest o wiele więcej, których jeszcze nie dotknęliśmy. Z przodu. Tak. Bardzo podoba mi się tweet Sama Altmana, w którym powiedział, że jego ulubioną analogią jest to, że ChatGPT jest w zasadzie rowerem elektrycznym dla umysłu, co ułatwia pracę. Tak, rower elektryczny dla umysłu. Sam Altman to powiedział, prawda. Steve Jobs powiedział, że Macintosh był rowerem dla umysłu, więc ChatGPT jest e-rowerem dla umysłu. OK. Powiedziałeś, że zawód inżyniera oprogramowania wkrótce się zmieni. Zastanawiam się jednak, odnosząc się do danych, które są dostępne na świecie, że nie wszystko, co sprawia, że inżynier oprogramowania jest inżynierem oprogramowania, jest dostarczane w rzeczywistych danych. Jest więc aspekt ludzki. Zastanawiam się więc, czy nie byłoby bardziej prawdopodobne, że przyszli inżynierowie oprogramowania do 2030 roku i później będą po prostu 10 000 razy bardziej efektywni, ale nadal będą musieli pozostać w roli apartamentu, ponieważ brakuje im wszystkich rzeczy, które czynią ich ludźmi, ponieważ danych po prostu nie ma. Nie ma miejsca na Ziemi, w którym jakaś etyczna zasada dotycząca życia w Bostonie lub Cambridge byłaby idealnie określona tak, jak w naszym umyśle. Tak, więc pytanie jest takie, że być może istnieje jakaś niewysłowiona jakość bycia ludzkim inżynierem oprogramowania, coś w naszym szkoleniu, naszej wiedzy o świecie, naszej etyce, naszej socjalizacji z innymi ludźmi, czego model nie uchwyci. Model językowy tego nie uchwyci. Być może w przyszłości inżynier oprogramowania nadal będzie inżynierem oprogramowania, ale będzie 10 000 razy bardziej produktywny niż obecnie. Myślę, że to dobre pytanie. Sądzę, że osiągniemy granicę tego, co możemy zrobić z językami programowania, narzędziami i rzeczami, o których ludzie muszą myśleć i je rozumieć. Oto jeden ze sposobów myślenia o tym. Żartobliwa odpowiedź brzmi: wyobraźmy sobie, że ludzie nadal są tymi, którzy głównie piszą kod, ale otrzymują przy tym cholernie dużo pomocy. Nadal będziemy musieli radzić sobie z CSS, tą stertą śmieci, z którą tysiące milionów inżynierów ma do czynienia każdego dnia. A powodem tego jest fakt, że jest to część naszego korpusu technologicznego. To część wiedzy ludzkości. To część stosu, z którego wszyscy korzystamy. Problem polega więc na tym, że istnieje limit przepustowości, który polega na tym, że indywidualny umysł musi przejść przez składniowy opis tego, co chce zrobić w tych okropnych językach, takich jak CSS i JavaScript oraz Python i Rust. I problem, który mam z tym jest taki, że myślę, że to naprawdę - jest to bariera dla faktycznego umożliwienia tego, co można zbudować za pomocą obliczeń, od faktycznego stania się rzeczywistością. To jak picie przez bardzo wąską słomkę. Myślę więc, że to, co musimy zrobić, to wyrwać ludzi z pętli i zmienić relacje między ludźmi a sposobem tworzenia oprogramowania, abyśmy mogli odblokować ten potencjał. Nie wiem, jak to dokładnie będzie wyglądać. Ale takie jest moje podstawowe przekonanie. Tak? Rozmowa dotyczyła głównie kodowania. A to jest o kodowaniu. A co z algorytmami? Jestem astrofizykiem. I w naszym przypadku, każdy teleskop jest jedną rzeczą na świecie. Po prostu - wszystkie są unikalne. Tak samo jak systemy przetwarzania danych. Mamy więc jakiś unikalny algorytm, który może zaprojektować lub zrozumieć tylko kilka osób na świecie. I nie spodziewałbym się, że duży model językowy pomoże w opracowaniu takiego algorytmu. Czy w biologii i bioinformatyce problemy są podobne? Czy uważasz, że nadal istnieje nisza dla LLM, która może pomóc w tym konkretnym obszarze? Tak. Pytanie brzmi: rozmawialiśmy o kodowaniu, ale nie o algorytmach. Kto wymyślił ten algorytm? Co było iskrą pomysłu, która stworzyła algorytm, który następnie przekładamy na te niezgrabne języki programowania? Myślę, że to bardzo dobra uwaga, ponieważ w tej chwili pojawia się pytanie - i wróciło to do mojej wcześniejszej uwagi o tym, że tak naprawdę nie znamy ograniczeń logicznego rozumowania tych modeli. I tak naprawdę nie wiem, czy gdybym powiedział modelowi, daj mu jakiś złożony problem, problem z analizą danych, który chcę rozwiązać, czy faktycznie mógłby wyprowadzić nowy algorytm, który nie był wcześniej znany. To dobre pytanie. Myślę, że tak, może nie w dzisiejszych modelach. Wierzę, że w przyszłości będzie to możliwe. Ale wtedy pytanie naprawdę wraca do podwójnego problemu: jak zapytać model, czego chcę? Jak wyrazić siebie? A następnie, jak najskuteczniej go nauczyć, aby uzyskać właściwą odpowiedź? Odpowiedzią może być więc symbioza między człowiekiem a modelem AI iterującym razem nad czymś, gdzie model AI robi rzeczy, w których jest dobry. Człowiek robi rzeczy, w których jest dobry. I już widzimy, że dzieje się tak z rzeczami takimi jak Copilot. Po prostu działa na bardzo niskim poziomie abstrakcji. Pisze cztery linijki kodu Pythona, aby odwrócić tę listę lub cokolwiek innego. Kiedy zaczynasz wchodzić na wyższy poziom abstrakcji, opracowujesz algorytmy, przeprowadzasz analizę danych, cokolwiek z tych rzeczy, myślę, że rodzaj narzędzia - to nie będzie Copilot w IDE. To będzie coś innego. Nie wiem, co to będzie. Może to Jupyter Notebooks na sterydach lub coś w tym stylu. Pozwól mi to zrobić. Zadam jeszcze tylko jedno pytanie. Zadam je tobie, ponieważ wcześniej podniosłeś rękę. Dzięki. Myślę więc, że mówisz o nowej erze programowania, w której programy AI są teraz abstrakcją tego, co robimy obecnie. Więc 15 lat w przyszłości będziemy mieli ludzi, którzy są przyzwyczajeni tylko do tego paradygmatu tworzenia programów. Czy uważasz, że klasyczny trening, który mamy dzisiaj, będzie pomocny? Tak, więc pytanie brzmi: czy sposób, w jaki szkolimy ludzi w dyscyplinach inżynierii oprogramowania, jest odpowiedni? Czy sposób, w jaki szkolimy dzisiaj, ma znaczenie w przyszłości, w której sztuczna inteligencja będzie robić więcej tego, prawda, lub więcej inżynierii podpowiedzi? To jest prawdziwe pytanie. I myślę, że mówiąc o tym na końcu, jako student informatyki w Cornell, tak, musiałem wziąć udział w zajęciach z EE i zrozumieć, jak działają obwody. To było ważne. A kiedy uczyłem tutaj, uczyłem systemów operacyjnych i programowania systemów oraz tego, czym jest stos, tego typu rzeczy. Więc ważne jest, aby mieć trochę tej podstawowej wiedzy. Ale pytanie brzmi, gdzie ostatecznie kładzie się nacisk na to, jak myślimy o tworzeniu programów i zarządzaniu nimi? Myślę, że byłoby błędem, gdyby, powiedzmy, programy uniwersyteckie nie zwracały na to uwagi i zakładały, że nauczanie informatyki w sposób, w jaki robiono to przez ostatnie 25 lat, jest właściwą rzeczą w tej przyszłości. Nie wiem, w jakim kierunku powinny one ewoluować. Mogę jednak powiedzieć, że kiedy ktoś wychodzi z zajęć akademickich i trafia do przemysłu, to już jest ogromna przepaść między tym, czego uczysz się na studiach, a tym, co musisz robić w prawdziwym świecie. Właśnie dlatego mamy takie rzeczy jak staże i inne metodologie. Być może więc celem akademickiej edukacji informatycznej niekoniecznie powinno być kształcenie zawodowe per se. Myślę jednak, że musimy zastanowić się, w jaki sposób ludzie rozumują na temat tych modeli? Mam nadzieję, że CS50, lub jakakolwiek inna równoważna klasa na innym uniwersytecie, może zagłębić się w zrozumienie niektórych mechanik stojących za takimi rzeczami, jak czat GPT, zrozumienie danych, ich pochodzenia, zrozumienie, w jaki sposób modele są konstruowane, jak są szkolone, jakie są ich ograniczenia, jak je oceniać. Ponieważ obawiam się, że uczniowie postrzegają to jako magiczną czarną skrzynkę, która zrobi wszystko za nich i nie mają krytycznego myślenia na ten temat. Z własnego doświadczenia wiem jednak, że jest to magiczna czarna skrzynka. I nie rozumiem, jak to działa. Ale nie przeszkadza mi to, ponieważ robi dla mnie tak wiele wspaniałych rzeczy. W każdym razie, dziękuję bardzo. Będę też w pobliżu na pizzę. [APPLAUSE]